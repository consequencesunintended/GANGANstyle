{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANGANSTYLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import zipfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 64\n",
    "initial_g_dimension = 8\n",
    "random_size = 16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImages(path):\n",
    "    archive = zipfile.ZipFile(path, 'r')\n",
    "    np_im_array = []\n",
    "\n",
    "    for name in archive.namelist():\n",
    "        imgfile = archive.open(name)\n",
    "        img = Image.open(imgfile)\n",
    "        np_im_array.append(np.array(img).reshape(dimension * dimension) / 255)\n",
    "\n",
    "    return np_im_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(images, batch_size):\n",
    "    indices = np.random.randint(0, len(images), batch_size)\n",
    "    batch_images = []\n",
    "    for i in indices:\n",
    "        batch_images.append(( images[i].reshape(dimension * dimension) ) * 2 - 1  )\n",
    "\n",
    "    return batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_fg_images = openImages('C:/resources/fake_photos_jpg.zip')\n",
    "real_fg_images = openImages('C:/resources/real_photos_jpg.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        alpha = 0.2\n",
    "\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=8*8*128)\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)        \n",
    "        reshaped_hidden1 = tf.reshape(hidden1,[-1,8,8,128] )  \n",
    "        \n",
    "        convo_1 = tf.layers.conv2d_transpose(inputs=reshaped_hidden1,filters=128,kernel_size=5,padding=\"same\", strides=2)\n",
    "        convo_1 = tf.maximum(alpha*convo_1,convo_1)\n",
    "\n",
    "        convo_2 = tf.layers.conv2d_transpose(inputs=convo_1,filters=128,kernel_size=5,padding=\"same\", strides=2)\n",
    "        convo_2 = tf.maximum(alpha*convo_2,convo_2)\n",
    "        \n",
    "        convo_3 = tf.layers.conv2d_transpose(inputs=convo_2,filters=128,kernel_size=5,padding=\"same\", strides=2)\n",
    "        convo_3 = tf.maximum(alpha*convo_3,convo_3)\n",
    "        \n",
    "        convo_4 = tf.layers.conv2d(inputs=convo_3,filters=1,kernel_size=5,padding=\"same\", strides=1,activation=tf.nn.tanh)\n",
    "        \n",
    "        output = tf.reshape(convo_4,[-1,dimension*dimension] )\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        alpha = 0.2\n",
    "        \n",
    "        reshaped_X = tf.reshape(X,[-1,dimension,dimension,1] )        \n",
    "        convo_1 = tf.layers.conv2d(inputs=reshaped_X,filters=64,kernel_size=5,padding=\"same\", strides=2)\n",
    "        convo_1 = tf.maximum(alpha*convo_1,convo_1)\n",
    "        \n",
    "        convo_2 = tf.layers.conv2d(inputs=convo_1,filters=64,kernel_size=5,padding=\"same\", strides=2)\n",
    "        convo_2 = tf.maximum(alpha*convo_2,convo_2)\n",
    "        \n",
    "        convo_3 = tf.layers.conv2d(inputs=convo_2,filters=64,kernel_size=5,padding=\"same\", strides=2)\n",
    "        convo_3 = tf.maximum(alpha*convo_3,convo_3)        \n",
    "        convo_3_flat = tf.reshape(convo_3,[-1,8*8*64])  \n",
    "        \n",
    "        logits = tf.layers.dense(convo_3_flat,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,dimension*dimension])\n",
    "noise_images = tf.placeholder(tf.float32,shape=[None,random_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model = generator(noise_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_logits_real, D_output_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_logits_fake, D_output_fake = discriminator(G_model,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_learning_rate = 1e-4\n",
    "gen_learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_loss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_real, labels=tf.ones_like(D_logits_real)) +\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake, labels=tf.zeros_like(D_logits_fake)))\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake, labels=tf.ones_like(D_logits_fake)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gen_vars = tf.trainable_variables('gen' )\n",
    "disc_vars = tf.trainable_variables('dis') \n",
    "\n",
    "D_trainer = tf.train.AdamOptimizer(disc_learning_rate, beta1=0.5).minimize(d_loss, var_list=disc_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(gen_learning_rate, beta1=0.5).minimize(g_loss, var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1500\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        num_batches = len(real_fg_images) // batch_size\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "\n",
    "            batch_images = next_batch( real_fg_images, batch_size )\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, random_size))\n",
    "            \n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, noise_images: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={real_images: batch_images, noise_images: batch_z})       \n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(\"Epoch: {} \".format(e + 1))\n",
    "        print(\"Time: {} \".format(end_time - start_time) )\n",
    "        \n",
    "        if e % 10 == 0:\n",
    "            \n",
    "            noise_sample = np.random.uniform(-1, 1, size=(20, random_size))\n",
    "            gen_sample = generator(noise_images ,reuse=True).eval(feed_dict={noise_images: noise_sample})\n",
    "            fig=plt.figure(figsize=(10, 10))\n",
    "            \n",
    "            for i in range(1,20):\n",
    "                reshaped_part = gen_sample[i]\n",
    "                fig.add_subplot(5, 5, i)\n",
    "                plt.imshow(reshaped_part.reshape(dimension, dimension),cmap='Greys')\n",
    "            plt.show()\n",
    "        \n",
    "        saver.save(sess, './models/ganganstyle.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    saver.restore(sess,'./models/ganganstyle.ckpt' )\n",
    "    noise_sample = np.random.uniform(-1, 1, size=(20, random_size))\n",
    "    gen_sample_fake = sess.run(generator(noise_images ,reuse=True),feed_dict={noise_images: noise_sample})\n",
    "    fig=plt.figure(figsize=(10, 10))\n",
    "    for i in range(1,20):\n",
    "        reshaped_part = gen_sample_fake[i]\n",
    "        fig.add_subplot(5, 5, i)\n",
    "        plt.imshow(reshaped_part.reshape(dimension, dimension),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gen_sample_fake[0].reshape(dimension,dimension), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
